# Resources

Other websites discussing AI jailbreaks and AI safety:

* [A new AI game: Give me ideas for crimes to do](https://simonwillison.net/2022/Dec/4/give-me-ideas-for-crimes-to-do/)
* [AI Notes](https://github.com/sw-yx/ai-notes/blob/main/TEXT.md)
* [Using GPT-Eliezer against ChatGPT Jailbreaking](https://www.lesswrong.com/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking)
* [Ways to get around ChatGPT's safeguards](https://twitter.com/davisblalock/status/1602600453555961856) twitter thread
* [Ways to get around ChatGPT's safeguards](https://news.ycombinator.com/item?id=33982683) hackernews discussions of the above
* [Reverse Engineered ChatGPT](https://github.com/acheong08/ChatGPT/)
* [SolidGoldMagikarp (plus, prompt generation)](https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation) lesswrong.com
* [Chatting Our Way Into Creating a Polymorphic Malware](https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware)
